Importre
Fromnltk.tokenizeimportsent_tokenize

#Textparagraph
Text=“So,keepworking.Keepstriving.Nevergiveup.Falldownseventimes,getupeight.Ease
isagreaterthreattoprogressthanhardship.Easeisagreaterthreattoprogressthanhardship.
So,keepmoving,keepgrowing,keeplearning.Seeyouatwork.”

#Removespecialcharactersanddigits
Text=re.sub(‘[^A-Za-z]+’,‘‘,text)

#Tokenizethesentences
Sentences=sent_tokenize(text)

#Calculatethescoreofeachsentencebasedonthenumberofwords
#Thesentenceswithmorewordswillhaveahigherscore
Scores={}
Forsentenceinsentences:
Words=sentence.split()
Score=len(words)
Scores[sentence]=score

#Sortthesentencesbasedontheirscores
Sorted_sentences=sorted(scores.items(),key=lambdax:x[1],reverse=True)

#Extractthetop2sentenceswiththehighestscoresasthesummary
Summary_sentences=[sentence[0]forsentenceinsorted_sentences[:2]]
Summary=““.join(summary_sentences)

#Printthesummary
Print(summary